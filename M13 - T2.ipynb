{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separe a base em treinamento e teste (25% para teste, 75% para treinamento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 11250\n",
      "Tamanho do teste: 3750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando os dados em treinamento e teste (75% treino, 25% teste)\n",
    "df_treino, df_teste = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verificando o tamanho de cada subconjunto\n",
    "print(f\"Tamanho do treino: {len(df_treino)}\")\n",
    "print(f\"Tamanho do teste: {len(df_teste)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rode uma regularização ridge com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o na base de testes. Qual o melhor modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha  R2_teste\n",
      "0  0.000  0.350900\n",
      "1  0.001  0.350900\n",
      "2  0.005  0.350900\n",
      "3  0.010  0.350900\n",
      "4  0.050  0.350899\n",
      "5  0.100  0.350899\n",
      "Melhor modelo: alpha = 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Separar X e y\n",
    "X = df_treino.drop(columns=['renda', 'data_ref', 'id_cliente'], errors='ignore')\n",
    "y = np.log(df_treino['renda'])  # log da renda\n",
    "\n",
    "# Base de teste\n",
    "X_teste = df_teste.drop(columns=['renda', 'data_ref', 'id_cliente'], errors='ignore')\n",
    "y_teste = np.log(df_teste['renda'])\n",
    "\n",
    "# Criar dummies para variáveis categóricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X_teste = pd.get_dummies(X_teste, drop_first=True)\n",
    "\n",
    "# Garantir mesmas colunas\n",
    "X_teste = X_teste.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Imputar valores ausentes (média para colunas numéricas)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_treino_imp = imputer.fit_transform(X)\n",
    "X_teste_imp = imputer.transform(X_teste)\n",
    "\n",
    "# Padronizar as variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino_imp)\n",
    "X_teste_scaled = scaler.transform(X_teste_imp)\n",
    "\n",
    "# Testar diferentes valores de alpha\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "resultados = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_treino_scaled, y)\n",
    "    y_pred = ridge.predict(X_teste_scaled)\n",
    "    r2 = r2_score(y_teste, y_pred)\n",
    "    resultados.append({'alpha': a, 'R2_teste': r2})\n",
    "\n",
    "# Exibir resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "print(resultados_df)\n",
    "\n",
    "# Melhor modelo\n",
    "melhor_alpha = resultados_df.loc[resultados_df['R2_teste'].idxmax(), 'alpha']\n",
    "print(f\"Melhor modelo: alpha = {melhor_alpha:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faça o mesmo que no passo 2, com uma regressão LASSO. Qual método chega a um melhor resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alpha  R2_teste\n",
      "0  0.0001  0.350784\n",
      "1  0.0010  0.350649\n",
      "2  0.0050  0.350396\n",
      "3  0.0100  0.349075\n",
      "4  0.0500  0.330409\n",
      "5  0.1000  0.300432\n",
      "Melhor modelo LASSO: alpha = 0.0001\n",
      "\n",
      "Comparação final:\n",
      "Ridge  R² = 0.3509\n",
      "LASSO  R² = 0.3508\n",
      "O modelo Ridge apresentou melhor desempenho.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Testar os mesmos valores de alpha\n",
    "alphas = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "resultados_lasso = []\n",
    "\n",
    "# Rodar o LASSO\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a, max_iter=10000)\n",
    "    lasso.fit(X_treino_scaled, y)\n",
    "    y_pred = lasso.predict(X_teste_scaled)\n",
    "    r2 = r2_score(y_teste, y_pred)\n",
    "    resultados_lasso.append({'alpha': a, 'R2_teste': r2})\n",
    "\n",
    "# Resultados do LASSO\n",
    "resultados_lasso_df = pd.DataFrame(resultados_lasso)\n",
    "print(resultados_lasso_df)\n",
    "\n",
    "# Melhor modelo LASSO\n",
    "melhor_alpha_lasso = resultados_lasso_df.loc[resultados_lasso_df['R2_teste'].idxmax(), 'alpha']\n",
    "print(f\"Melhor modelo LASSO: alpha = {melhor_alpha_lasso:.4f}\")\n",
    "\n",
    "# Comparar Ridge x LASSO\n",
    "melhor_ridge = resultados_df['R2_teste'].max()\n",
    "melhor_lasso = resultados_lasso_df['R2_teste'].max()\n",
    "\n",
    "print(\"\\nComparação final:\")\n",
    "print(f\"Ridge  R² = {melhor_ridge:.4f}\")\n",
    "print(f\"LASSO  R² = {melhor_lasso:.4f}\")\n",
    "\n",
    "if melhor_lasso > melhor_ridge:\n",
    "    print(\"O modelo LASSO apresentou melhor desempenho.\")\n",
    "elif melhor_lasso < melhor_ridge:\n",
    "    print(\"O modelo Ridge apresentou melhor desempenho.\")\n",
    "else:\n",
    "    print(\"Ambos os modelos tiveram desempenho equivalente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rode um modelo stepwise. Avalie o na base de testes. Qual o melhor resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adicionado: tempo_emprego com p=0.000000\n",
      "Adicionado: sexo_M com p=0.000000\n",
      "Adicionado: tipo_renda_Empresário com p=0.000000\n",
      "Adicionado: educacao_Superior completo com p=0.000000\n",
      "Adicionado: idade com p=0.000000\n",
      "Adicionado: posse_de_imovel com p=0.000000\n",
      "Adicionado: qtd_filhos com p=0.002739\n",
      "Adicionado: tipo_renda_Servidor público com p=0.012171\n",
      "Adicionado: estado_civil_Viúvo com p=0.015638\n",
      "\n",
      "Variáveis selecionadas:\n",
      "['tempo_emprego', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo', 'idade', 'posse_de_imovel', 'qtd_filhos', 'tipo_renda_Servidor público', 'estado_civil_Viúvo']\n",
      "\n",
      "R² na base de teste: 0.3638\n",
      "\n",
      "Resumo do modelo:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  renda   R-squared:                       0.353\n",
      "Model:                            OLS   Adj. R-squared:                  0.352\n",
      "Method:                 Least Squares   F-statistic:                     564.1\n",
      "Date:                Thu, 30 Oct 2025   Prob (F-statistic):               0.00\n",
      "Time:                        16:44:12   Log-Likelihood:                -10197.\n",
      "No. Observations:                9320   AIC:                         2.041e+04\n",
      "Df Residuals:                    9310   BIC:                         2.049e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                           7.1097      0.040    176.905      0.000       7.031       7.188\n",
      "tempo_emprego                   0.0608      0.001     51.025      0.000       0.058       0.063\n",
      "sexo_M                          0.7997      0.016     50.075      0.000       0.768       0.831\n",
      "tipo_renda_Empresário           0.1641      0.017      9.491      0.000       0.130       0.198\n",
      "educacao_Superior completo      0.1130      0.016      7.229      0.000       0.082       0.144\n",
      "idade                           0.0055      0.001      6.183      0.000       0.004       0.007\n",
      "posse_de_imovel                 0.0915      0.016      5.768      0.000       0.060       0.123\n",
      "qtd_filhos                      0.0311      0.010      3.041      0.002       0.011       0.051\n",
      "tipo_renda_Servidor público     0.0632      0.026      2.472      0.013       0.013       0.113\n",
      "estado_civil_Viúvo              0.1178      0.049      2.418      0.016       0.022       0.213\n",
      "==============================================================================\n",
      "Omnibus:                        0.900   Durbin-Watson:                   1.996\n",
      "Prob(Omnibus):                  0.638   Jarque-Bera (JB):                0.862\n",
      "Skew:                           0.017   Prob(JB):                        0.650\n",
      "Kurtosis:                       3.033   Cond. No.                         278.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Garantir que não há valores ausentes na variável usada\n",
    "df = df.dropna(subset=['tempo_emprego', 'renda'])\n",
    "\n",
    "# Criar dummies e converter tudo para float\n",
    "df_dummies = pd.get_dummies(df.drop(columns=['data_ref', 'id_cliente']),\n",
    "                            drop_first=True).astype(float)\n",
    "\n",
    "# Separar variáveis dependente e independentes\n",
    "X = df_dummies.drop(columns=['renda'])\n",
    "y = np.log(df_dummies['renda'])\n",
    "\n",
    "# Dividir treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Função stepwise com tratamento para tipos numéricos\n",
    "def stepwise_selection(X, y, initial_list=[], threshold_in=0.05, threshold_out=0.10, verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=float)\n",
    "        for new_col in excluded:\n",
    "            try:\n",
    "                model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_col]]))).fit()\n",
    "                new_pval[new_col] = model.pvalues[new_col]\n",
    "            except Exception:\n",
    "                new_pval[new_col] = np.nan\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval is not None and best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f\"Adicionado: {best_feature} com p={best_pval:.6f}\")\n",
    "\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]  # exclui intercepto\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval is not None and worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f\"Removido: {worst_feature} com p={worst_pval:.6f}\")\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return included\n",
    "\n",
    "# Executar seleção stepwise\n",
    "variaveis_final = stepwise_selection(X_treino, y_treino)\n",
    "\n",
    "# Ajustar modelo final\n",
    "modelo_stepwise = sm.OLS(y_treino, sm.add_constant(X_treino[variaveis_final])).fit()\n",
    "\n",
    "# Avaliar desempenho no teste\n",
    "y_pred = modelo_stepwise.predict(sm.add_constant(X_teste[variaveis_final]))\n",
    "r2_teste = r2_score(y_teste, y_pred)\n",
    "\n",
    "print(\"\\nVariáveis selecionadas:\")\n",
    "print(variaveis_final)\n",
    "print(f\"\\nR² na base de teste: {r2_teste:.4f}\")\n",
    "print(\"\\nResumo do modelo:\")\n",
    "print(modelo_stepwise.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao comparar os parâmetros entre os modelos Ridge, LASSO e Stepwise, observa-se que as magnitudes e os sinais dos coeficientes principais permanecem consistentes, indicando estabilidade das relações entre as variáveis explicativas e a renda. O modelo Stepwise apresentou um R² ligeiramente superior (0.364) e manteve apenas variáveis estatisticamente significantes (p < 0.05), demonstrando maior parcimônia sem perda de desempenho. Assim, o modelo Stepwise é o mais adequado entre os testados, por combinar boa capacidade preditiva com simplicidade e coerência estatística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partindo dos modelos que você ajustou, tente melhorar o na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, código aplica técnicas de engenharia de variáveis para melhorar o desempenho do modelo de regressão. A ideia é capturar relações não lineares e interações entre variáveis que o modelo linear simples não consegue representar. Para isso, foram criadas transformações como quadrados, produtos e razões entre variáveis relevantes (por exemplo, idade², idade * tempo_emprego e renda_per_capita). Em seguida, as variáveis categóricas foram convertidas em dummies, os dados padronizados e o modelo Ridge foi reajustado com o mesmo parâmetro ótimo de regularização. Esse processo busca aumentar o R² na base de teste, mantendo um equilíbrio entre precisão e simplicidade do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo R² na base de teste: 0.6374\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Cópia da base já tratada\n",
    "df_mod = df.copy()\n",
    "\n",
    "# Criação de novas variáveis (exemplos)\n",
    "df_mod['idade2'] = df_mod['idade'] ** 2\n",
    "df_mod['tempo_emprego2'] = df_mod['tempo_emprego'] ** 2\n",
    "df_mod['idade_tempo'] = df_mod['idade'] * df_mod['tempo_emprego']\n",
    "df_mod['filhos_por_pessoa'] = df_mod['qtd_filhos'] / (df_mod['qt_pessoas_residencia'] + 1)\n",
    "df_mod['renda_per_capita'] = df_mod['renda'] / (df_mod['qt_pessoas_residencia'] + 1)\n",
    "\n",
    "# Remover valores ausentes e gerar dummies\n",
    "df_mod = df_mod.dropna(subset=['tempo_emprego'])\n",
    "df_dummies = pd.get_dummies(df_mod.drop(columns=['data_ref', 'id_cliente']), drop_first=True).astype(float)\n",
    "\n",
    "# Divisão treino/teste\n",
    "X = df_dummies.drop(columns=['renda'])\n",
    "y = np.log(df_dummies['renda'])\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Padronizar\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino)\n",
    "X_teste_scaled = scaler.transform(X_teste)\n",
    "\n",
    "# Reajustar modelo (ex: Ridge com melhor alpha anterior)\n",
    "modelo = Ridge(alpha=0.001)\n",
    "modelo.fit(X_treino_scaled, y_treino)\n",
    "\n",
    "# Avaliar\n",
    "y_pred = modelo.predict(X_teste_scaled)\n",
    "r2_teste = r2_score(y_teste, y_pred)\n",
    "print(f\"Novo R² na base de teste: {r2_teste:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O script abaixo compara o modelo Ridge original (com variáveis simples) com uma versão melhorada que inclui transformações não lineares e interações (como idade² e idade * tempo_emprego). Ambas as versões passam por padronização e uso de Ridge com o mesmo alpha para manter a comparação justa.\n",
    "Por fim, o código exibe os dois valores de R² na base de teste, permitindo avaliar se as novas variáveis realmente aumentaram o poder preditivo do modelo.\n",
    "Esse tipo de abordagem é essencial em modelagem estatística, pois busca melhorar a performance sem comprometer a interpretabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² base original: 0.3647\n",
      "R² base transformada: 0.3669\n",
      "O modelo com transformações apresentou melhor desempenho.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ==========================\n",
    "# Base original\n",
    "# ==========================\n",
    "df_original = df.copy()\n",
    "df_original = df_original.dropna(subset=['tempo_emprego'])\n",
    "\n",
    "# Criar dummies\n",
    "df_original_dummies = pd.get_dummies(df_original.drop(columns=['data_ref', 'id_cliente']), drop_first=True).astype(float)\n",
    "\n",
    "# Separar treino e teste\n",
    "X = df_original_dummies.drop(columns=['renda'])\n",
    "y = np.log(df_original_dummies['renda'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Padronizar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ajustar modelo Ridge\n",
    "ridge_original = Ridge(alpha=0.001)\n",
    "ridge_original.fit(X_train_scaled, y_train)\n",
    "r2_original = r2_score(y_test, ridge_original.predict(X_test_scaled))\n",
    "\n",
    "# ==========================\n",
    "# Base com transformações\n",
    "# ==========================\n",
    "df_mod = df.copy()\n",
    "df_mod['idade2'] = df_mod['idade'] ** 2\n",
    "df_mod['tempo_emprego2'] = df_mod['tempo_emprego'] ** 2\n",
    "df_mod['idade_tempo'] = df_mod['idade'] * df_mod['tempo_emprego']\n",
    "df_mod['filhos_por_pessoa'] = df_mod['qtd_filhos'] / (df_mod['qt_pessoas_residencia'] + 1)\n",
    "df_mod = df_mod.dropna(subset=['tempo_emprego'])\n",
    "df_mod_dummies = pd.get_dummies(df_mod.drop(columns=['data_ref', 'id_cliente']), drop_first=True).astype(float)\n",
    "\n",
    "X2 = df_mod_dummies.drop(columns=['renda'])\n",
    "y2 = np.log(df_mod_dummies['renda'])\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "X2_train_scaled = scaler2.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler2.transform(X2_test)\n",
    "\n",
    "ridge_mod = Ridge(alpha=0.001)\n",
    "ridge_mod.fit(X2_train_scaled, y2_train)\n",
    "r2_mod = r2_score(y2_test, ridge_mod.predict(X2_test_scaled))\n",
    "\n",
    "# ==========================\n",
    "# Comparação dos resultados\n",
    "# ==========================\n",
    "print(f\"R² base original: {r2_original:.4f}\")\n",
    "print(f\"R² base transformada: {r2_mod:.4f}\")\n",
    "if r2_mod > r2_original:\n",
    "    print(\"O modelo com transformações apresentou melhor desempenho.\")\n",
    "else:\n",
    "    print(\"O modelo original teve desempenho semelhante ou superior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste uma árvore de regressão e veja se consegue um melhor com ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (base de teste): 0.3734\n",
      "MSE: 0.5102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cópia da base já tratada\n",
    "df_tree = df.copy()\n",
    "\n",
    "# Remover colunas irrelevantes e valores ausentes\n",
    "df_tree = df_tree.drop(columns=['data_ref', 'id_cliente'])\n",
    "df_tree = df_tree.dropna(subset=['tempo_emprego'])\n",
    "\n",
    "# Criar dummies para variáveis categóricas\n",
    "df_tree_dummies = pd.get_dummies(df_tree, drop_first=True).astype(float)\n",
    "\n",
    "# Separar variáveis explicativas e resposta\n",
    "X = df_tree_dummies.drop(columns=['renda'])\n",
    "y = np.log(df_tree_dummies['renda'])\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Ajustar a árvore de regressão\n",
    "tree = DecisionTreeRegressor(max_depth=6, min_samples_leaf=50, random_state=42)\n",
    "tree.fit(X_treino, y_treino)\n",
    "\n",
    "# Avaliar desempenho\n",
    "y_pred = tree.predict(X_teste)\n",
    "r2_tree = r2_score(y_teste, y_pred)\n",
    "mse_tree = mean_squared_error(y_teste, y_pred)\n",
    "\n",
    "print(f\"R² (base de teste): {r2_tree:.4f}\")\n",
    "print(f\"MSE: {mse_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de árvore de regressão apresentou o melhor desempenho entre todos os testados, com R² de 0.3734 e MSE de 0.5102 na base de teste. Isso indica que ele conseguiu capturar relações não lineares e interações entre as variáveis que os modelos lineares (Ridge, LASSO e Stepwise) não conseguiram representar adequadamente. Assim, a árvore de regressão se mostra uma alternativa mais eficaz para prever a renda, oferecendo maior capacidade preditiva sem a necessidade de suposições estritas de linearidade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
